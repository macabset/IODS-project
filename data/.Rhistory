# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
scaled_crim <- boston_scaled$crim
summary(scaled_crim)
crim_quant <- quantile(scaled_crim)
boston_scaled <- scale(Boston)
scaled_crim <- boston_scaled$crim
boston_scaled <- scale(Boston)
boston_scaled<- as.data.frame(boston_scaled)
scaled_crim <- boston_scaled$crim
summary(scaled_crim)
crim_quant <- quantile(scaled_crim)
crim_quant
# create a categorical variable 'crime'
crime <- cut(scaled_crim, breaks = crim_quant, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
# look at the table of the new factor crime
table(crime)
# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
random <- sample(n,  size = n * 0.8)
# train set
train <- boston_scaled[random,]
# test set
test <- boston_scaled[-random,]
#save crime from test
correct_classes <- test$crime
# remove crime from test data
test <- dplyr::select(test, -crime)
# linear discriminant analysis
lda.fit <- lda(formula= crime ~ ., data = train)
lda.fit
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot the lda results
plot(lda.fit, dimen = 2, col=classes, pch=classes)
lda.arrows(lda.fit, myscale = 1)
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
data("Boston")
boston_scaled2 <- scale(Boston)
summary(boston_scaled2)
class(boston_scaled2)
data("Boston")
boston_scaled2 <- scale(Boston)
summary(boston_scaled2)
class(boston_scaled2)
boston_scaled<- as.data.frame(boston_scaled)
boston_scaled
data("Boston")
boston_scaled2 <- scale(Boston)
summary(boston_scaled2)
class(boston_scaled2)
boston_scaled2<- as.data.frame(boston_scaled2)
boston_scaled2
# manhattan distance matrix
dist_man <- dist(boston_scaled2, method="manhattan")
# look at the summary of the distances
summary(dist_man)
dist_eu <- dist(Boston)
# look at the summary of the distances
summary(dist_eu)
dist_eu <- dist(boston_scaled2)
# look at the summary of the distances
summary(dist_eu)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
pairs(boston_scaled2, col = km$cluster)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
ggpairs(boston_scaled2, col = km$cluster)
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
ggpairs(boston_scaled2, col = km$cluster)
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
qqpairs(boston_scaled2, col = km$cluster)
?ggpairs()
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
ggpairs(boston_scaled2, col = km$cluster)
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
pairs(boston_scaled2, col = km$cluster)
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
ggpairs(boston_scaled2, aes(colour = km$cluster))
library(ggplot2)
ggpairs(boston)
library(ggplot2)
ggpairs(boston)
data(flea)
ggpairs(flea, columns = 2:4)
library(ggplot2)
data(flea)
ggpairs(flea, columns = 2:4)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
pairs(boston_scaled2, aes(colour = km$cluster))
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
qqpairs(boston_scaled2, aes(colour = km$cluster))
??qqpairs
??qqpairs()
?ggpairs()
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
ggpairs(boston_scaled2, ggplot::aes(colour = km$cluster))
data(flea)
ggpairs(flea, columns = 2:4)
detach("package:ggplot2", unload=TRUE)
library("ggplot2", lib.loc="~/R/win-library/3.3")
data(flea)
ggpairs(flea, columns = 2:4)
library(ggplot2)
set.seed(123)
# euclidean distance matrix
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 2)
# plot the Boston dataset with clusters
pairs(boston_scaled2, aes(colour = km$cluster))
#Veikko Isotalo
#4.2.2017
#Data wrangling: Week 3
#data from: https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION
myfun <- function(projectWD){
setwd(projectWD)
library(magrittr)
library(dplyr)
library(tidyr)
library(ggplot2)
}
k <- "/Users/veikko/Desktop/datakurssi/IODS-project/data"
myfun(k)
getwd()
math <- read.csv("student-mat.csv", header = T, sep = ";")
por <- read.csv("student-por.csv", header = T, sep = ";")
dim(math)
dim(por)
colnames(math)
head(math)
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu",
"Fedu","Mjob","Fjob","reason","nursery","internet")
math_por <- math %>%
left_join(por, by = join_by, suffix = c(".math", ".por")) %>%
drop_na()
# alternatively: math_por <- inner_join(math, por, by = join_by, suffix = c(".math", ".por"))
glimpse(math_por)
alc <- math_por %>%
select(one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]
# for every column name not used for joining...
for(column_name in notjoined_columns) {
two_columns <- select(math_por, starts_with(column_name))
first_column <- select(two_columns, 1)[[1]]
if(is.numeric(first_column)) {
alc[column_name] <- round(rowMeans(two_columns))
} else {
alc[column_name] <- first_column
}
}
# glimpse at the new combined data
glimpse(alc)
alc <- alc %>%
mutate(alc_use = (Walc + Dalc)/2)
alc <- alc %>%
mutate(high_use = alc_use > 2)
glimpse(alc)
write.csv(alc, file = "alcohol_data.csv", row.names = F)
??filter()
??tail()
?tail()
#set workind directory
setwd("Z:/Jatko-opinnot/Tilastotiede 2016/IODS/IODS-project/Data")
#check working directory
getwd()
#read the data "Human development"
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
#read the data "Gender inequality"
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
#check the Human development dataset
dim(hd)
str(hd)
summary(hd)
#rename variables of the Human development dataset
names(hd)[names(hd)=="HDI.Rank"] <- "hdi_r"
names(hd)[names(hd)=="Country"] <- "country"
names(hd)[names(hd)=="Human.Development.Index..HDI."] <- "hdi_i"
names(hd)[names(hd)=="Life.Expectancy.at.Birth"] <- "life_exp"
names(hd)[names(hd)=="Expected.Years.of.Education"] <- "educ_exp"
names(hd)[names(hd)=="Mean.Years.of.Education"] <- "educ_mean"
names(hd)[names(hd)=="Gross.National.Income..GNI..per.Capita"] <- "gni_c"
names(hd)[names(hd)=="GNI.per.Capita.Rank.Minus.HDI.Rank"] <- "gni_hdi_dif"
#check that renaming worked OK
names(hd)
#check the Gender inequality dataset
dim(gii)
str(gii)
summary(gii)
#rename variables of the Gender inequality dataset
names(gii)[names(gii)=="GII.Rank"] <- "gii_r"
names(gii)[names(gii)=="Country"] <- "country"
names(gii)[names(gii)=="Gender.Inequality.Index..GII."] <- "gii_i"
names(gii)[names(gii)=="Maternal.Mortality.Ratio"] <- "mat_mort"
names(gii)[names(gii)=="Adolescent.Birth.Rate"] <- "b_rate"
names(gii)[names(gii)=="Percent.Representation.in.Parliament"] <- "parl"
names(gii)[names(gii)=="Population.with.Secondary.Education..Female."] <- "educ_f"
names(gii)[names(gii)=="Population.with.Secondary.Education..Male."] <- "educ_m"
names(gii)[names(gii)=="Labour.Force.Participation.Rate..Female."] <- "labour_f"
names(gii)[names(gii)=="Labour.Force.Participation.Rate..Male."] <- "labour_m"
#check that renaming worked OK
names(gii)
#create new variable the ratio of Female and Male populations with secondary education in each country
gii$educ_rat <- gii$educ_f/gii$educ_m
summary(gii$educ_rat)
#create new variable the ratio of labour force participation of females and males in each country
gii$labour_rat <- gii$labour_f/gii$labour_m
summary(gii$labour_rat)
#check that everything worked OK
summary(gii)
# access the dplyr library
library(dplyr)
# use the variable "country" as identifier
join_by <- c("country")
# join the two datasets by the selected identifiers
human <- inner_join(hd, gii, by = join_by)
# see the new column names
colnames(human)
# glimpse at the new data
glimpse(human)
#compare the three datasets
dim(human)
dim(hd)
dim(gii)
#Everythinig worked OK!
dim(hd)
gii$educ_rat <- gii$educ_f/gii$educ_m
summary(gii$educ_rat)
summary(gii)
colnames(human)
glimpse(human)
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
getwd()
human <- read.csv("data/human.csv", sep=",", header= T, row.names = 1)
str(human)
dim(human)
head(human)
summary(human)
library(GGally); library(dplyr); library(corrplot)
cor(human)
ggpairs(human)
cor(human) %>% corrplot( method="circle", type="upper") + ggtitle("Correlation plot between variables in human")
#Packages we need in this workout
library(GGally)
library(dplyr)
library(corrplot)
library(FactoMineR)
library(ggplot2)
library(tidyr)
```{r}
#Packages we need in this workout
library(GGally)
library(dplyr)
library(corrplot)
library(FactoMineR)
library(ggplot2)
library(tidyr)
getwd()
human <- read.csv("data/human.csv", sep=",", header= T, row.names = 1)
str(human)
dim(human)
head(human)
summary(human)
?ggtitle()
cor(human)
ggpairs(human)
cor(human) %>% corrplot( method="circle", type="upper") + ggtitle("Correlation plot between variables in human")
cor(human)
ggpairs(human)
p <- cor(human) %>% corrplot( method="circle", type="upper")
ggplot(p, title = "Correlations between variables in human data"))
ggplot(p, title = "Correlations between variables in human data")
?corrplot()
cor(human)
ggpairs(human)
p <- cor(human) %>% corrplot( method="circle", type="upper", title= "Correlations between variables in human data")
cor(human) %>% corrplot( method="circle", type="upper", title= "Correlations between variables in human data")
cor(human)
ggpairs(human)
cor(human) %>% corrplot( method="circle", type="upper", title= "Correlations between variables in human data")
?ggpairs()
?biplot()
pca_human <- prcomp(human)
pca_human
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
require(graphics)
biplot(princomp(USArrests))
?ggtitle()
pca_human <- prcomp(human)
pca_human
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"), title= "Is this working")
pca_human <- prcomp(human)
pca_human
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
pca_human <- prcomp(human)
pca_human
p <- biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
p + labs(x="New label")
pca_human <- prcomp(human)
pca_human
p <- biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
p + labs(title="New label")
pca_human <- prcomp(human)
pca_human
p <- biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
p + ggplot2::labs(title="New label")
human.std <- scale(human)
pca_human2 <- prcomp(human.std)
biplot(pca_human2, choices= 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
s <- summary(pca_human2)
pca_pr <- round(100*s$importance[2, ], digits = 1)
# create object pc_lab to be used as axis labels
pc_lab <- paste0(names(pca_pr), " (", pca_pr, "%)")
# draw a biplot
biplot(pca_human2, cex = c(0.8, 1), col = c("grey40", "deeppink2"), xlab = pc_lab[1], ylab = pc_lab[2])
#Draw a pca with only arrows
res.pca = PCA(human, scale.unit= TRUE, ncp=5, graph=T)
#ggplot2, dplyr, tidyr and FactoMineR available
data(tea)
my_tea <- data.frame(tea)
dim(my_tea)
str(my_tea)
summary(my_tea)
gather(my_tea) %>% ggplot(aes(value))  + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
?ggtitle()
gather(my_tea) %>% ggplot(aes(value), title("Working?"))  + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
gather(my_tea) %>% ggplot(aes(value, title ="Working?"))  + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
gather(my_tea) %>% ggplot(aes(value)  + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
gather(my_tea) %>% ggplot(aes(value)  + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)
gather(my_tea) %>% ggplot(aes(value))  + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)
gather(my_tea) %>% ggplot(aes(value))  + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
keep_columns <- c("breakfast", "sex", "price", "healthy", "spirituality", "friends", "Tea", "tearoom")
my_tea1 <- dplyr::select(my_tea, one_of(keep_columns))
gather(my_tea1) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
#Columns for our subset my_tea1
keep_columns <- c("breakfast", "sex", "price", "healthy", "spirituality", "friends", "Tea", "tearoom")
my_tea1 <- dplyr::select(my_tea, one_of(keep_columns))
#Picturing with bars
gather(my_tea1) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
mca <- MCA(my_tea1, graph = FALSE)
# summary of the model
summary(mca)
# visualize MCA
plot(mca, invisible=c("ind"), habillage="quali")
mca <- MCA(my_tea1, graph = FALSE, col.var="contrib")
mca <- MCA(my_tea1, graph = FALSE)
# summary of the model
summary(mca)
# visualize MCA, individual points are invisible showing only variables.
plot(mca, col.var="contrib", invisible=c("ind"), habillage="quali")
mca <- MCA(my_tea1, graph = FALSE)
# summary of the model
summary(mca)
# visualize MCA, individual points are invisible showing only variables.
plot(mca, col.var="contrib", invisible=c("ind"))
mca <- MCA(my_tea1, graph = FALSE)
# summary of the model
summary(mca)
# visualize MCA, individual points are invisible showing only variables.
plot(mca, invisible=c("ind"), habillage="quali")
mca <- MCA(my_tea1, graph = FALSE)
# summary of the model
summary(mca)
# visualize MCA, individual points are invisible showing only variables.
plot(mca, invisible=c("ind"), col.var="contrib")
mca <- MCA(my_tea1, graph = FALSE)
# summary of the model
summary(mca)
# visualize MCA, individual points are invisible showing only variables.
plot(mca, invisible=c("ind"),  habillage="quali")
res.mca=MCA(my_tea1)
plotellipses(res.mca,keepvar=1:4)
res.mca=MCA(my_tea1)
plotellipses(res.mca,keepvar=3)
getwd()
