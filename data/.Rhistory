#Data Wrangling for the dimensionality
#This data is originally from United Nations Development Programme(http://hdr.undp.org/en/content/human-development-index-hdi)
#Setting the working directory to my computer:
library(Matrix)
library(ggplot2)
library(dplyr)
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
#Read files Human development and gender inequality to R
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
#We have 2 datasets that we eventually want to combine, but let's first see what we have.
#Human development focuses what are the factors that determine how well our country ranks when looking at human development. It has 8 variables and 195 observations. Variables are both numeric and character.
#Gender inequality tries to grasp the inequality between men and women in achievements. It focuses on health, empowerement and work markets. This dataset contains 10 variables and also 195 observations( since it's based on the same resaerch??). This dataset has also both numeric and character variables.
summary(hd)
summary(gii)
#Let's give our variables shorter names, so they will be easier to use further.
colnames(hd)
colnames(hd)[1] <-"Rank"
colnames(hd)[3] <-"HDI"
colnames(hd)[4] <- "Life_expect"
colnames(hd)[5] <- "Edu_expect"
colnames(hd)[6] <- "Edu_years"
colnames(hd)[7] <- "GNI"
colnames(hd)[8] <- "GNI-Rank"
colnames(hd)
colnames(gii)
colnames(gii)[1] <- "Rank"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "Mom_death"
colnames(gii)[5] <- "Young_birth"
colnames(gii)[6] <- "Present_parl"
colnames(gii)[7] <- "Edu2F"
colnames(gii)[8] <- "Edu2M"
colnames(gii)[9] <- "LabF"
colnames(gii)[10] <- "LabM"
colnames(gii)
#Mutate: gii
#2 new variables
gii <- mutate(gii, Sex_edu2 = Edu2F / Edu2M)
gii <- mutate(gii, Lab_ratio = LabF/LabM)
colnames(gii)
#Join datasets by country
join_by <- c("Country")
hdi_gii <- inner_join(hd, gii, by= join_by, suffix= c(".hd", ".gii"))
colnames(hdi_gii)
#Saving project to data file
write.csv(hdi_gii, file = "human.csv", row.names = FALSE)
human <- read.csv("human.csv", sep=",", header= T)
#And final check that everything works.
str(human)
#This is continuum for last week's data wrangling. We are continuing with the same data.
#1. mutate data GNi to numeric
human <- mutate(human, GNI = as.numeric(human$GNI))
str(human)
#2. Keep columns: (described in the meta file above):  "Country", "Edu2.FM", "Labo.FM", "Edu.Exp", "Life.Exp", "GNI", "Mat.Mor", "Ado.Birth", "Parli.F"
keep_columns <- c("Country", "Sex_edu2", "Lab_ratio", "Edu_expect", "Life_expect", "GNI", "Mom_death", "Young_birth", "Present_parl")
human <- select(human, one_of(keep_columns))
str(human)
#3.Remove rows with missing values
#create column with missing values and then filter leaving NA's out.
complete.cases(human)
data.frame(human[-1], comp = complete.cases(human))
human_ <- filter(human, complete.cases(human))
complete.cases(human_)
#Let's clean the column country and filter regions out
#The last 7 rows with column country are infact regions instead of countries.
last <- nrow(human) - 7
# I'll choose everything until the last 7 observations, the 155's being Nigeria.
human[1:155, ]
#4. add countries as rownames and remove country as column
rownames(human_) <- human_$Country
#Remove country as column
human_ <- dplyr::select(human_, -Country)
str(human_)
#override the old data:
write.csv(human_, file = "human.csv", row.names = TRUE)
human <- read.csv("human.csv", sep=",", header= T)
str(human)
summary(human)
complete.cases(human)
#It now has 9 variables, but that is because of the rownames included.
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
human <- read.table("human.csv", sep = ",", header = TRUE)
str(human)
dim(human)
summary(human)
complete.cases(human)
library(GGally); library(dplyr); library(corrplot)
cor(human)
#16.2.2017//Maija Absetz
#Data Wrangling for the dimensionality
#This data is originally from United Nations Development Programme(http://hdr.undp.org/en/content/human-development-index-hdi)
#Setting the working directory to my computer:
library(Matrix)
library(ggplot2)
library(dplyr)
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
#Read files Human development and gender inequality to R
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
#We have 2 datasets that we eventually want to combine, but let's first see what we have.
#Human development focuses what are the factors that determine how well our country ranks when looking at human development. It has 8 variables and 195 observations. Variables are both numeric and character.
#Gender inequality tries to grasp the inequality between men and women in achievements. It focuses on health, empowerement and work markets. This dataset contains 10 variables and also 195 observations( since it's based on the same resaerch??). This dataset has also both numeric and character variables.
summary(hd)
summary(gii)
#Let's give our variables shorter names, so they will be easier to use further.
colnames(hd)
colnames(hd)[1] <-"Rank"
colnames(hd)[3] <-"HDI"
colnames(hd)[4] <- "Life_expect"
colnames(hd)[5] <- "Edu_expect"
colnames(hd)[6] <- "Edu_years"
colnames(hd)[7] <- "GNI"
colnames(hd)[8] <- "GNI-Rank"
colnames(hd)
colnames(gii)
colnames(gii)[1] <- "Rank"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "Mom_death"
colnames(gii)[5] <- "Young_birth"
colnames(gii)[6] <- "Present_parl"
colnames(gii)[7] <- "Edu2F"
colnames(gii)[8] <- "Edu2M"
colnames(gii)[9] <- "LabF"
colnames(gii)[10] <- "LabM"
colnames(gii)
#Mutate: gii
#2 new variables
gii <- mutate(gii, Sex_edu2 = Edu2F / Edu2M)
gii <- mutate(gii, Lab_ratio = LabF/LabM)
colnames(gii)
#Join datasets by country
join_by <- c("Country")
hdi_gii <- inner_join(hd, gii, by= join_by, suffix= c(".hd", ".gii"))
colnames(hdi_gii)
#Saving project to data file
write.csv(hdi_gii, file = "human.csv", row.names = FALSE)
human <- read.csv("human.csv", sep=",", header= T)
#And final check that everything works.
str(human)
#This is continuum for last week's data wrangling. We are continuing with the same data.
#1. mutate data GNi to numeric
human <- mutate(human, GNI = as.numeric(human$GNI))
str(human)
#2. Keep columns: (described in the meta file above):  "Country", "Edu2.FM", "Labo.FM", "Edu.Exp", "Life.Exp", "GNI", "Mat.Mor", "Ado.Birth", "Parli.F"
keep_columns <- c("Country", "Sex_edu2", "Lab_ratio", "Edu_expect", "Life_expect", "GNI", "Mom_death", "Young_birth", "Present_parl")
human <- select(human, one_of(keep_columns))
str(human)
#3.Remove rows with missing values
#create column with missing values and then filter leaving NA's out.
complete.cases(human)
data.frame(human[-1], comp = complete.cases(human))
human_ <- filter(human, complete.cases(human))
complete.cases(human_)
#Let's clean the column country and filter regions out
#The last 7 rows with column country are infact regions instead of countries.
last <- nrow(human) - 7
# I'll choose everything until the last 7 observations, the 155's being Nigeria.
human[1:155, ]
#4. add countries as rownames and remove country as column
rownames(human_) <- human_$Country
#Remove country as column
human_ <- dplyr::select(human_, -Country)
str(human_)
#override the old data:
write.csv(human_, file = "human.csv", row.names = FALSE)
human <- read.csv("human.csv", sep=",", header= T)
str(human)
summary(human)
complete.cases(human)
#It now has 9 variables, but that is because of the rownames included.
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
human <- read.table("human.csv", sep = ",", header = TRUE)
str(human)
dim(human)
summary(human)
complete.cases(human)
library(GGally); library(dplyr); library(corrplot)
cor(human)
ggpairs(human)
cor(human) %>% corrplot()
library(GGally); library(dplyr); library(corrplot)
cor(human)
ggpairs(human)
cor(human) %>% corrplot( method="circle", type="upper")
prcomp(human)
prcomp(human)
biplot(human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
prcomp(human)
biplot(human, choices = 1:2)
pca_human <- prcomp(human)
pca_human
biplot(pca_human, choices = 1:2)
pca_human <- prcomp(human)
pca_human
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
human.std <- scale(human)
pca_human2 <- prcomp(human.std)
biplot(pca_human2, choices= 1:2)
human.std <- scale(human)
pca_human2 <- prcomp(human.std)
biplot(pca_human2, choices= 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
pca_human <- prcomp(human)
pca_human
biplot(pca_human, choices = 1:2, cex = c(0.8, 1.5), col= c("grey40", "deeppink2"))
pca_human <- prcomp(human)
pca_human
biplot(pca_human, choices = 1:2, cex = c(0.8, 1), col= c("grey40", "deeppink2"))
# Regression analysis - why attitude matters
*This week I have completed DataCamp exercises, peer reviewed Rstudio excersice 1 and surprisingly enough learned for the first time to create regression models in the RStudio excercise 2. This has been an excellent opportunity to learn to interpret regression model many-sidedly and thoroughly.*
##Part 1
is the data wrangling exercise, which doesn't show on my course diary. If you are interested, go and check in my github: https://github.com/macabset/IODS-project/blob/master/data/create_learning2014.R
```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
full_learn14<- read.table( "http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
library(dplyr)
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D07","D14","D22","D30")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
deep_columns <- select(full_learn14, one_of(deep_questions))
full_learn14$deep <- rowMeans(deep_columns)
surface_columns <- select(full_learn14, one_of(surface_questions))
full_learn14$surf <- rowMeans(surface_columns)
strategic_columns <- select(full_learn14, one_of(strategic_questions))
full_learn14$stra <- rowMeans(strategic_columns)
New_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
sub_learn14 <- select(full_learn14, one_of(New_columns))
colnames(sub_learn14)[2] <- "age"
colnames(sub_learn14)[3] <- "attitude"
colnames(sub_learn14)[7]<- "points"
colnames(sub_learn14)
str(sub_learn14)
sub_learn14 <- filter(sub_learn14, points >! 0)
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
write.csv(sub_learn14, file = "learning2014.csv", row.names = FALSE)
lrn2014 <- read.csv("learning2014.csv")
head(lrn2014)
```
##Part 2: Analysis (max 15p)
###2.1: Exploring our dataset
```{r}
str(lrn2014)
dim(lrn2014)
```
Here we can see the learning2014 dataset, whih has 7 variables with 166 observations.
This questionnary conserning students's approaches to learning has been collected from a course:" Introduction to Social Statistics, fall 2014" (Finnish).
Dataset has been modified so that questions have been combined to combined variables and 0 values in variable points have been removed.
```{r}
summary(lrn2014)
library(ggplot2)
```
In our summary we can see that all variables except gender are numeric with discrete values.
###2.2 Picturing our dataset
```{r}
A <- ggplot(lrn2014, aes(x= attitude, y=points, col=gender))
B <- A +geom_point()
C <- B + geom_smooth(method = "lm")
Figure1 <- C + ggtitle("Figure 1. The relationship between attitude and points")
Figure1
```
Figure 1 shows us how attitude towards statistics correlate to the points of the exam. In this case, such as in many others, motivation explains partly success.
###EXTRA: Combinig strategic learning to points.
```{r}
D <- ggplot(lrn2014, aes(x=stra, y=points, col=gender))
D1 <- D + geom_point()
D2 <- D1 + geom_smooth(method="lm")
Figure2 <- D2 + ggtitle("Figure 2. The relationship between strategic learning and points")
Figure2
```
If we look at Figure 2 there seems to be a very small linear relationship between strategic learning and exam points. If student used strategic learning method in general, he or she might have gained a bit better exam points.
###2.3 Regression model
*Choosing explaining variables*
```{r}
library(GGally)
ggpairs(lrn2014, lower= list(combo = wrap("facethist", bins = 20)))
```
As we can see in our plot matrix, variables attitude, stra and surf correlate the most with the points. Lets try those as explanatory variables in our regression model.
*Explaining points with attitude, strategic learning  and surface learning*
Regression model 1
```{r}
my_reg <- lm(points ~ attitude + stra + surf, data = lrn2014 )
summary(my_reg)
```
Attitude seems to be the only one statistically significant in explaining points. This result is compatitive with our result in Figure 2, where correlation between strategic learning and points was bearly noticeable.
Let's remove first surf and see again our model
Regression model 2
```{r}
my_reg2 <- lm(points ~ attitude + stra, data = lrn2014)
summary(my_reg2)
```
The strategic learning gives still too high p-value, so we cannot exclude it being significant by chance.
Let's try our regression model with only attitude explaining it.
Regression model 3
```{r}
my_reg3 <- lm(points ~ attitude, data=lrn2014)
summary(my_reg3)
```
It seems that attitude towards statistics is our key explanatory variable to exam points. The more positive attitude toward statistics in general the better outcome in exam.
However, we should consider our model as a whole, so let's check first our R-squared values.
### 2.4 Interpreting R-squared
R-squared in our regression model tells us how well our model fits to observations. To simplify, the bigger the R-squared the better our model seems to fit to observations.
Our 3 tests of regression model show that our Multiple R-squared lowers each time we drop a variable. That happens, because it increases every time you add a variable, so drop in itself isn't a bad thing.  What we also see is that the 2nd test has the highest *adjusted R-square*. This should mean that even though we have more variables than in the 3rd one, it seems to be a better model in quality, and not just better fit because we add or lose variables.
I conclude that we still should consider bringing back the strategic learning to our multiple regression model, even though its p-value is over magical line of 0.05. Now we can check if regression model 2 is really viable by checking the residuals in our model.
###2.5 Errors in our model
Let's check Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage with our regression model 2.
```{r}
errors <- plot(my_reg2, which= c(1,2,5), par(mfrow= c(2,2)))
```
In plot 1 we see, that values are reaasonably well scattered through out the area, which means that errors make no pattern, as is expected from a good model.
In plot 2 we see, that our observations lines up to a line, so the errors seem to be normally distributed. This is consistent with our assumption, atlhough our model is less suitable in the both ends of values.
In plot 3 we see, that no single observation has too much weight on the model, leverage line stayes under 0.05 in the whole plot.
###2.6 To conclude
our regression model 2, with explanatory variables attitude and strategic learning, exam points are explained with linear model. Considering the r-squared and checking with residuals, it indeed seems that the 2nd regression model best explains points. That means the more positive attitude towards statistics and the more strategically you wish to learn, the better outcome you get from statistics exam.
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
write.csv(sub_learn14, file = "learning2014.csv", row.names = FALSE)
lrn2014 <- read.csv("learning2014.csv")
head(lrn2014)
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
write.csv(sub_learn14, file = "learning2014.csv", row.names = FALSE)
lrn2014 <- read.csv("learning2014.csv")
head(lrn2014)
```{r}
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
#RStudio exercise 2, take 2
#Maija Absetz//27.1.2017
#1. Data Wrangling (max 5p)
#sET THE WOTKING DIRECTORY TO MAKE DATA MORE OPEN
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
#1.1 Getting our data to R and exploring its content:
full_learn14<- read.table( "http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
str(full_learn14)
dim(full_learn14)
#Our data has got 60 variables and 184 observations in those 60 variables.
#The structure shows what kind of observations do we have in our variables: factors, numbers, levels.
install.packages("dplyr")
library(dplyr)
#1.2 Exploring and creating altogether 7 variables: gender, age, attitude, deep, stra, surf, points.
full_learn14$gender
full_learn14$Age
full_learn14$Points
#Create stra, deep and surf
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D07","D14","D22","D30")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
#Combine questions with mean and rename
deep_columns <- select(full_learn14, one_of(deep_questions))
full_learn14$deep <- rowMeans(deep_columns)
surface_columns <- select(full_learn14, one_of(surface_questions))
full_learn14$surf <- rowMeans(surface_columns)
strategic_columns <- select(full_learn14, one_of(strategic_questions))
full_learn14$stra <- rowMeans(strategic_columns)
#Pick columns for your sub_data
New_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
sub_learn14 <- select(full_learn14, one_of(New_columns))
#Rename all to small letters
colnames(sub_learn14)[2] <- "age"
colnames(sub_learn14)[3] <- "attitude"
colnames(sub_learn14)[7]<- "points"
colnames(sub_learn14)
str(sub_learn14)
#Exclude "0" values out of "points"
sub_learn14 <- filter(sub_learn14, points >! 0)
#1.3 Save to iods-project as csv format
?write.csv
install.packages("dplyr")
getwd()
write.csv(sub_learn14, file = "learning2014.csv", row.names = FALSE)
lrn2014 <- read.csv("learning2014.csv")
head(lrn2014)
getwd()
lrn2014 <- read.csv("learning2014.csv")
head(lrn2014)
getwd()
#Maija Absetz// 4.2.2017
#This is Rstudio exercice 2 data wrangling part for student alcohol consumption.
getwd()
full_mat <- read.csv("student-mat.csv", header = TRUE, sep=";")
full_por <- read.csv("student-por.csv", header = TRUE, sep=";")
str(full_mat)
str(full_por)
dim(full_mat)
dim(full_por)
# Both our data sets have 33 variables. Data from math course has 295 observations and data from portuguese course has 649 observations.
#Join the 2 datasets:
library(dplyr)
#Common columns: "school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery","internet"
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
joined_math_por <- inner_join(full_mat, full_por, by= join_by, suffix= c(".full_mat", ".full_por"))
colnames(joined_math_por)
str(joined_math_por)
dim(joined_math_por)
#Now we have 53 variables and 382 observations.
#Lets concentrate on alcohol consumption.
#The if-else structure
alc <- select(joined_math_por, one_of(join_by))
#Not joined columns
notjoined_columns <- colnames(full_mat)[!colnames(full_mat) %in% join_by]
notjoined_columns
##Making a logical rule for the not joined columns:
# for every column name not used for joining...
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(joined_math_por, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- first_column
}
}
glimpse(alc)
#Create alcohol usage + hgh alcohol usage to alcohol consumption data
library(ggplot2)
alc <- mutate(alc, alc_use= (Dalc + Walc)/2)
alc <- mutate(alc, high_use = (alc_use) > 2)
glimpse (alc)
#Saving project to data file
write.csv(alc, file = "create_alc.csv", row.names = FALSE)
alc2016 <- read.csv("create_alc.csv")
getwd()
alc2016 <- read.csv("create_alc.csv")
setwd()
getwd()
alc2016 <- read.csv("create_alc.csv")
getwd()
getwd()
setwd(C:/Users/Petri/Documents/GitHub/IODS-project/data/)
setwd(C:"/Users/Petri/Documents/GitHub/IODS-project/data/")
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
full_mat <- read.csv("student-mat.csv", header = TRUE, sep=";")
full_por <- read.csv("student-por.csv", header = TRUE, sep=";")
str(full_mat)
str(full_por)
dim(full_mat)
dim(full_por)
# Both our data sets have 33 variables. Data from math course has 295 observations and data from portuguese course has 649 observations.
#Join the 2 datasets:
library(dplyr)
#Common columns: "school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery","internet"
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
joined_math_por <- inner_join(full_mat, full_por, by= join_by, suffix= c(".full_mat", ".full_por"))
colnames(joined_math_por)
str(joined_math_por)
dim(joined_math_por)
#Now we have 53 variables and 382 observations.
#Lets concentrate on alcohol consumption.
#The if-else structure
alc <- select(joined_math_por, one_of(join_by))
#Not joined columns
notjoined_columns <- colnames(full_mat)[!colnames(full_mat) %in% join_by]
notjoined_columns
##Making a logical rule for the not joined columns:
# for every column name not used for joining...
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(joined_math_por, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- first_column
}
}
glimpse(alc)
#Create alcohol usage + hgh alcohol usage to alcohol consumption data
library(ggplot2)
alc <- mutate(alc, alc_use= (Dalc + Walc)/2)
alc <- mutate(alc, high_use = (alc_use) > 2)
glimpse (alc)
#Saving project to data file
write.csv(alc, file = "create_alc.csv", row.names = FALSE)
alc2016 <- read.csv("create_alc.csv")
getwd()
alc2016 <- read.csv("create_alc.csv")
View(alc2016)
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
alc2016 <- read.csv("create_alc.csv")
setwd("C:/Users/Petri/Documents/GitHub/IODS-project/data/")
getwd()
alc2016 <- read.csv("create_alc.csv")
head(alc2016)
library(ggplot2)
g1 <- ggplot(alc2016, aes(x = high_use, y = studytime, col=sex))
g2 <- g1 + geom_boxplot() + ggtitle("Figure 1.Studytime by high use of alcohol and gender")
g2
